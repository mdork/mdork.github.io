<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: June 29, 2023 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css" media="print" onload="this.media='all'">

  
  
  
    
    

    
    
    
    
      
      
    
    
    

    
    
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.a5693e00993770ec38b7d5b7b107ddd1.css" />

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  


























  
  
  






  <meta name="author" content="Michael Dorkenwald" />





  

<meta name="description" content="PhD Student" />



<link rel="alternate" hreflang="en-us" href="https://mdork.github.io/publication-type/1/" />
<link rel="canonical" href="https://mdork.github.io/publication-type/1/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />
<meta property="twitter:image" content="https://mdork.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png" />
<meta property="og:site_name" content="Michael Dorkenwald" />
<meta property="og:url" content="https://mdork.github.io/publication-type/1/" />
<meta property="og:title" content="1 | Michael Dorkenwald" />
<meta property="og:description" content="PhD Student" /><meta property="og:image" content="https://mdork.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta property="og:updated_time" content="2022-06-24T00:00:00&#43;00:00" />
  










  
  
  

  
  
    <link rel="alternate" href="/publication-type/1/index.xml" type="application/rss+xml" title="Michael Dorkenwald" />
  

  


  
  <title>1 | Michael Dorkenwald</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   "  >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js"></script>

  




  <div class="page-header header--fixed">
    












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Michael Dorkenwald</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Michael Dorkenwald</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#publications"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#contact"><span>Contact</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    













  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>1</h1>

  

  
</div>



<div class="universal-wrapper">
  

  
  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/cvpr21/" >SCVRL: Shuffled Contrastive Video Representation Learning</a>
    </div>

    
    <a href="/publication/cvpr21/"  class="summary-link">
      <div class="article-style">
        <b style="font-size:120%;color:#008080">CVPR 2022 I3D-IVU workshop</b> <b style="font-size:120%;color:#E08040"></b><br> We propose SCVRL, a novel contrastive-based framework for self-supervised learning for videos. Differently from previous contrast learning based methods that mostly focus on learning visual semantics (e.g., CVRL), SCVRL is capable of learning both semantic and motion patterns.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Michael Dorkenwald</span>, <span >
      Fanyi Xiao</span>, <span >
      Biagio Brattoli</span>, <span >
      Joseph Tighe</span>, <span >
      Davide Modolo</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://assets.amazon.science/df/11/45a0d07a43dda1db5aa87e163a67/scvrl-shuffled-contrastive-video-representation-learning.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/cvpr21/cite.bib">
  Cite
</a>














  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.amazon.science/publications/scvrl-shuffled-contrastive-video-representation-learning" target="_blank" rel="noopener">
    Project Page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      <a href="/publication/cvpr21/" >
        <img src="/publication/cvpr21/featured_hu65a5f564cab82e3f88eaeeab796cb32f_562216_150x0_resize_q90_h2_lanczos_3.webp" height="160" width="150"
            alt="SCVRL: Shuffled Contrastive Video Representation Learning" loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/andy_iccv/" >iPOKE: Poking a Still Image for Controlled Stochastic Video Synthesis </a>
    </div>

    
    <a href="/publication/andy_iccv/"  class="summary-link">
      <div class="article-style">
        <b style="font-size:120%;color:#008080">ICCV 2021</b> <b style="font-size:120%;color:#E08040"></b><br> We present iPOKE, a model for locally controlled, stochastic video synthesis based on poking a single pixel in a static scene, that enables users to animate still images only with simple mouse drags.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Andreas Blattmann</span>, <span >
      Timo Milbich</span>, <span class="author-highlighted">
      Michael Dorkenwald</span>, <span >
      Bjoern Ommer</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2107.02790.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/andy_iccv/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/CompVis/ipoke" target="_blank" rel="noopener">
  Code
</a>













  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://compvis.github.io/ipoke/" target="_blank" rel="noopener">
    Project Page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      <a href="/publication/andy_iccv/" >
        <img src="/publication/andy_iccv/featured_hu48d9f47ca18c1777917d71ff91ae24dc_332099_150x0_resize_q90_h2_lanczos_3.webp" height="110" width="150"
            alt="iPOKE: Poking a Still Image for Controlled Stochastic Video Synthesis " loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/i2v/" >Stochastic Image-to-Video Synthesis using cINNs</a>
    </div>

    
    <a href="/publication/i2v/"  class="summary-link">
      <div class="article-style">
        <b style="font-size:120%;color:#008080">CVPR 2021</b> <b style="font-size:120%;color:#E08040"></b><br> We present a framework for both controlled and stochastic image-to-video synthesis. We bridge the gap between the image and video domain using conditional invertible neural networks and account for the inherent ambiguity with a dedicated, learned scene dynamics representation.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Michael Dorkenwald</span>, <span >
      Timo Milbich</span>, <span >
      Andreas Blattmann</span>, <span >
      Robin Rombach</span>, <span >
      Konstantinos G. Derpanis</span>, <span >
      Björn Ommer</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2105.04551.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/i2v/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/CompVis/image2video-synthesis-using-cINNs" target="_blank" rel="noopener">
  Code
</a>













  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://compvis.github.io/image2video-synthesis-using-cINNs/" target="_blank" rel="noopener">
    Project Page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      <a href="/publication/i2v/" >
        <img src="/publication/i2v/featured_hu1384f38540f2a0e7db5c11d076c51a90_740667_150x0_resize_q90_h2_lanczos_3.webp" height="155" width="150"
            alt="Stochastic Image-to-Video Synthesis using cINNs" loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/behavior_driven/" >Behavior-Driven Synthesis of Human Dynamics</a>
    </div>

    
    <a href="/publication/behavior_driven/"  class="summary-link">
      <div class="article-style">
        <b style="font-size:120%;color:#008080">CVPR 2021</b> <b style="font-size:120%;color:#E08040"></b><br> We present a model for human motion synthesis which learns a dedicated representation of human dynamics independent of postures. Using this representation, we are able to change the behavior of a person depicted in an arbitrary posture or to even directly transfer behavior observed in a given video sequence.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Andreas Blattmann</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Timo Milbich</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span class="author-highlighted">
      Michael Dorkenwald</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Bjoern Ommer</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2103.04677.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/behavior_driven/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/CompVis/behavior-driven-video-synthesis" target="_blank" rel="noopener">
  Code
</a>













  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://compvis.github.io/behavior-driven-video-synthesis/" target="_blank" rel="noopener">
    Project Page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      <a href="/publication/behavior_driven/" >
        <img src="/publication/behavior_driven/featured_hube8d28474a12a0d5f7f9a2345cc4f2a5_258032_150x0_resize_q90_h2_lanczos_3.webp" height="65" width="150"
            alt="Behavior-Driven Synthesis of Human Dynamics" loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/andy_cvpr/" >Understanding Object Dynamics for Interactive Image-to-Video Synthesis</a>
    </div>

    
    <a href="/publication/andy_cvpr/"  class="summary-link">
      <div class="article-style">
        <b style="font-size:120%;color:#008080">CVPR 2021</b> <b style="font-size:120%;color:#E08040"></b><br> We propose an approach for interactive image-to-video synthesis that learns to understand the relations between the distinct body parts of articulated objects from unlabeled video data, thus enabling synthesis of videos showing natural object dynamics as responses to local interactions.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span >
      Andreas Blattmann</span>, <span >
      Timo Milbich</span>, <span class="author-highlighted">
      Michael Dorkenwald</span>, <span >
      Bjoern Ommer</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Blattmann_Understanding_Object_Dynamics_for_Interactive_Image-to-Video_Synthesis_CVPR_2021_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/andy_cvpr/cite.bib">
  Cite
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/CompVis/interactive-image2video-synthesis" target="_blank" rel="noopener">
  Code
</a>













  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://compvis.github.io/interactive-image2video-synthesis/" target="_blank" rel="noopener">
    Project Page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      <a href="/publication/andy_cvpr/" >
        <img src="/publication/andy_cvpr/featured_huc633972a4c3e6c55131e9ab906725378_229780_150x0_resize_q90_h2_lanczos_3.webp" height="113" width="150"
            alt="Understanding Object Dynamics for Interactive Image-to-Video Synthesis" loading="lazy">
      </a>
    
  </div>
</div>

  
    







  







  


<div class="media stream-item view-compact">
  <div class="media-body">

    <div class="section-subheading article-title mb-0 mt-0">
      <a href="/publication/cvpr20/" >Unsupervised Magnification of Posture Deviations across Subjects</a>
    </div>

    
    <a href="/publication/cvpr20/"  class="summary-link">
      <div class="article-style">
        <b style="font-size:120%;color:#008080">CVPR 2020</b> <b style="font-size:120%;color:#E08040"></b><br> An approach to unsupervised magnification of posture differences across individuals despite large deviations in appearance.
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  <span class="author-highlighted">
      Michael Dorkenwald</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Uta Buechler</span><i class="author-notes fas fa-info-circle" data-toggle="tooltip" title="Equal contribution"></i>, <span >
      Bjoern Ommer</span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Dorkenwald_Unsupervised_Magnification_of_Posture_Deviations_Across_Subjects_CVPR_2020_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>



<a href="#" class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal"
        data-filename="/publication/cvpr20/cite.bib">
  Cite
</a>











  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=i2e6J4baLbY" target="_blank" rel="noopener">
  Video
</a>




  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary btn-page-header btn-sm" href="https://compvis.github.io/magnify-posture-deviations/" target="_blank" rel="noopener">
    Project Page</a>


    </div>
    

  </div>
  <div class="ml-3">
    
    
      
      <a href="/publication/cvpr20/" >
        <img src="/publication/cvpr20/featured_hu42fa6939c86980fc93b5917c8a13297e_646115_150x0_resize_q90_h2_lanczos_3.webp" height="89" width="150"
            alt="Unsupervised Magnification of Posture Deviations across Subjects" loading="lazy">
      </a>
    
  </div>
</div>

  

  

</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.d26509351aa0ff874abbee824e982e9b.js"></script>




  

  
  

  






























<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>










<script src="/en/js/wowchemy.min.e973d49cb2d568aa6f8eaf3638337473.js"></script>







  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>


















</body>
</html>
